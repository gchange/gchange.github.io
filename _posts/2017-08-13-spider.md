---
layout: default
title:  爬虫篇之基础入门
---

<h1>{{ page.title }}</h1>

[github](https://github.com/gchange/spider)

## 爬取网站的3种常见方法
* 爬取网站地图
* 遍历每个页面的数据库ID
* 跟踪网页链接

### 网站地图
方便搜索引擎机器人找到网站中的页面而编写的描述了网站架构的文档。
* [网站地图](https://zh.wikipedia.org/wiki/%E7%B6%B2%E7%AB%99%E5%9C%B0%E5%9C%96)
* [sitemap语法介绍](http://wiki.jikexueyuan.com/project/seo/24.html)

### 遍历每个页面的数据库ID
这只适用与特定结构的网站，限制条件较多。

### 跟踪网页链接
由一个跟页面进入，逐步深入到其他链接，这种方式更像一个普通用户的行为。

## 高级功能

### 解析robots.txt
为了避免下载禁止爬取的URL，爬取前需先解析robots.txt

### 支持代理
有些网站会屏蔽某些IP进行访问或者会会同一个IP获取做限制。

### 下载限速
如果我们爬取网站的速度过快，就会面临被封禁或是造成服务器过载的风险。为了降低这些风险，我们可以在两次下载之间添加延时，从而对爬虫限速。

### 爬虫陷阱
一些网站会动态生成页面内容，这样会出现无限多的链接，这种情况称为爬虫陷阱；为了避免进入爬虫陷阱，一个简单的方法是记录当前网页的深度，爬虫之会爬取一定深度以内的页面。

## 数据提取

### 提取方式

#### [正则表达式](https://docs.python.org/3/howto/regex.html)
针对特定网页编写正则表达式，从中提取数据  

##### 优点
 * 灵活  

##### 缺点
 * 难以构造
 * 可读性差
 * 不能适应变化

### [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/#)
BeautifulSoup将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象,所有对象可以归纳为4种: Tag , NavigableString , BeautifulSoup , Comment .

* Tag: 通过tag的名字对相应属性进行增删查改
* NavigableString: tag中的字符串
* BeautifulSoup: 文档的全部内容
* Comment: 注释

## 下载缓存
由于爬虫会在爬虫过程中，会从上一个页面的内容中提取出页面包含的连接， 这会使得爬虫的爬取会出现环，同时，爬取重复页面也会极大降低爬取效率，为了避免这些情况，需要对将要爬取的链接进行过滤。

### 布隆过滤
由于爬取的页面数量十分庞大，需要在有限的内容中缓存页面爬取情况并快速判断该链接是否已经爬取，同时，将少量未爬取的页面误判为已爬取是可以接受的。  
根据以上特点，bloom filter经常用作爬虫当中过滤已爬取链接的数据结构。


#### 参考：
* [用Python写网络爬虫](http://www.epubit.com.cn/book/onlinechapter/42493)
* [网站地图](https://zh.wikipedia.org/wiki/%E7%B6%B2%E7%AB%99%E5%9C%B0%E5%9C%96)
* [sitemap语法介绍](http://wiki.jikexueyuan.com/project/seo/24.html)
* [Beautiful Soup 4.2.0 文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/#)
* [Bloom Filter概念和原理](http://blog.csdn.net/jiaomeng/article/details/1495500)

<p>{{ page.date | date_to_string }}</p>
